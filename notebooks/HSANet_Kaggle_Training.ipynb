{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9d4d39",
   "metadata": {},
   "source": [
    "# HSANet: Hybrid Scale-Attention Network for Brain Tumor Classification\n",
    "## Complete Training Pipeline for Kaggle\n",
    "\n",
    "**Improvements over v1:**\n",
    "1. âœ… Fixed AUC-ROC calculation (was broken)\n",
    "2. âœ… Added Expected Calibration Error (ECE) for uncertainty validation\n",
    "3. âœ… Proper evidential deep learning implementation\n",
    "4. âœ… GradCAM visualization for interpretability\n",
    "5. âœ… Comprehensive ablation study\n",
    "6. âœ… Statistical significance testing\n",
    "\n",
    "**Author:** HSANet Team  \n",
    "**Date:** January 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f98da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (if needed)\n",
    "!pip install -q timm scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aff6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import timm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, cohen_kappa_score, matthews_corrcoef,\n",
    "    roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from scipy import stats\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a37258",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Training configuration\"\"\"\n",
    "    # Paths - UPDATE FOR YOUR ENVIRONMENT\n",
    "    DATA_DIR = Path(\"/kaggle/input/brain-tumor-mri-dataset\")  # Kaggle\n",
    "    # DATA_DIR = Path(\"./data/brain-tumor-mri-dataset\")  # Local\n",
    "    OUTPUT_DIR = Path(\"./outputs\")\n",
    "    \n",
    "    # Model\n",
    "    BACKBONE = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
    "    NUM_CLASSES = 4\n",
    "    CLASS_NAMES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "    CLASS_NAMES_DISPLAY = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "    \n",
    "    # Training\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 3e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    \n",
    "    # Image\n",
    "    IMG_SIZE = 224\n",
    "    \n",
    "    # Cross-validation\n",
    "    N_FOLDS = 5\n",
    "    \n",
    "    # Loss\n",
    "    LAMBDA_KL = 0.2\n",
    "    LAMBDA_FOCAL = 0.3\n",
    "    KL_ANNEALING_EPOCHS = 10\n",
    "    \n",
    "    # Device\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Seed\n",
    "    SEED = 42\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(Config.SEED)\n",
    "Config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Device: {Config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b9357",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbfe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, data_dir: Path, split: str = 'Training', transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(Config.CLASS_NAMES)}\n",
    "        \n",
    "        split_dir = self.data_dir / split\n",
    "        if not split_dir.exists():\n",
    "            split_dir = self.data_dir\n",
    "        \n",
    "        for class_name in Config.CLASS_NAMES:\n",
    "            class_dir = split_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "                    for img_path in class_dir.glob(ext):\n",
    "                        self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} images from {split}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def get_transforms(split='train'):\n",
    "    if split == 'train':\n",
    "        return T.Compose([\n",
    "            T.Resize((Config.IMG_SIZE + 32, Config.IMG_SIZE + 32)),\n",
    "            T.RandomCrop(Config.IMG_SIZE),\n",
    "            T.RandomHorizontalFlip(0.5),\n",
    "            T.RandomRotation(15),\n",
    "            T.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            T.ColorJitter(0.2, 0.2, 0.2),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            T.RandomErasing(0.1)\n",
    "        ])\n",
    "    return T.Compose([\n",
    "        T.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = BrainTumorDataset(Config.DATA_DIR, split='Training')\n",
    "test_dataset = BrainTumorDataset(Config.DATA_DIR, split='Testing')\n",
    "\n",
    "# Class distribution\n",
    "labels = [s[1] for s in train_dataset.samples]\n",
    "print(\"\\nClass Distribution (Training):\")\n",
    "for i, name in enumerate(Config.CLASS_NAMES_DISPLAY):\n",
    "    count = labels.count(i)\n",
    "    print(f\"  {name}: {count} ({count/len(labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc843c",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveMultiScaleModule(nn.Module):\n",
    "    \"\"\"AMSM: Adaptive Multi-Scale Module with Dilated Convolutions\"\"\"\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1, dilation=1),\n",
    "            nn.BatchNorm2d(in_channels), nn.ReLU(inplace=True))\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=2, dilation=2),\n",
    "            nn.BatchNorm2d(in_channels), nn.ReLU(inplace=True))\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=4, dilation=4),\n",
    "            nn.BatchNorm2d(in_channels), nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels * 3, in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels, 3),\n",
    "            nn.Softmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m1, m2, m4 = self.branch1(x), self.branch2(x), self.branch4(x)\n",
    "        concat = torch.cat([self.pool(m1), self.pool(m2), self.pool(m4)], dim=1).flatten(1)\n",
    "        w = self.fc(concat)\n",
    "        return w[:,0:1,None,None]*m1 + w[:,1:2,None,None]*m2 + w[:,2:3,None,None]*m4 + x\n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c = x.shape[:2]\n",
    "        avg = self.fc(self.avg_pool(x).view(b, c))\n",
    "        mx = self.fc(self.max_pool(x).view(b, c))\n",
    "        return x * torch.sigmoid(avg + mx).view(b, c, 1, 1)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, 7, padding=3, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        concat = torch.cat([x.mean(1, keepdim=True), x.max(1, keepdim=True)[0]], dim=1)\n",
    "        return x * torch.sigmoid(self.bn(self.conv(concat)))\n",
    "\n",
    "\n",
    "class DualAttentionModule(nn.Module):\n",
    "    \"\"\"DAM: Channel â†’ Spatial Attention\"\"\"\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention(channels)\n",
    "        self.spatial_att = SpatialAttention()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.spatial_att(self.channel_att(x))\n",
    "\n",
    "\n",
    "class EvidentialClassifier(nn.Module):\n",
    "    \"\"\"Evidential Deep Learning Head\"\"\"\n",
    "    def __init__(self, in_features: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512), nn.ReLU(inplace=True), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.fc(x)\n",
    "        evidence = F.softplus(logits)\n",
    "        alpha = evidence + 1.0\n",
    "        S = alpha.sum(dim=1, keepdim=True)\n",
    "        probs = alpha / S\n",
    "        \n",
    "        unc_total = self.num_classes / S.squeeze()\n",
    "        entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)\n",
    "        unc_aleatoric = entropy / np.log(self.num_classes)\n",
    "        unc_epistemic = (unc_total - unc_aleatoric).clamp(min=0)\n",
    "        \n",
    "        return {'logits': logits, 'evidence': evidence, 'alpha': alpha, 'probs': probs,\n",
    "                'uncertainty_total': unc_total, 'uncertainty_aleatoric': unc_aleatoric,\n",
    "                'uncertainty_epistemic': unc_epistemic}\n",
    "\n",
    "\n",
    "class HSANet(nn.Module):\n",
    "    \"\"\"HSANet: Hybrid Scale-Attention Network\"\"\"\n",
    "    def __init__(self, num_classes=4, pretrained=True, use_amsm=True, use_dam=True):\n",
    "        super().__init__()\n",
    "        self.use_amsm, self.use_dam = use_amsm, use_dam\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            Config.BACKBONE, pretrained=pretrained, features_only=True, out_indices=[2, 3, 4])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, Config.IMG_SIZE, Config.IMG_SIZE)\n",
    "            self.feature_dims = [f.shape[1] for f in self.backbone(dummy)]\n",
    "        \n",
    "        if use_amsm:\n",
    "            self.amsm = nn.ModuleList([AdaptiveMultiScaleModule(d) for d in self.feature_dims])\n",
    "        if use_dam:\n",
    "            self.dam = nn.ModuleList([DualAttentionModule(d) for d in self.feature_dims])\n",
    "        \n",
    "        self.pools = nn.ModuleList([nn.AdaptiveAvgPool2d(1) for _ in self.feature_dims])\n",
    "        self.classifier = EvidentialClassifier(sum(self.feature_dims), num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        processed = []\n",
    "        for i, feat in enumerate(features):\n",
    "            if self.use_amsm: feat = self.amsm[i](feat)\n",
    "            if self.use_dam: feat = self.dam[i](feat)\n",
    "            processed.append(self.pools[i](feat).flatten(1))\n",
    "        return self.classifier(torch.cat(processed, dim=1))\n",
    "\n",
    "\n",
    "# Test model\n",
    "model = HSANet().to(Config.DEVICE)\n",
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"HSANet parameters: {params/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457e437",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidentialLoss(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "        \n",
    "    def forward(self, outputs, targets):\n",
    "        alpha, probs = outputs['alpha'], outputs['probs']\n",
    "        S = alpha.sum(dim=1, keepdim=True)\n",
    "        y = F.one_hot(targets, self.num_classes).float()\n",
    "        \n",
    "        # Evidence-weighted CE\n",
    "        loss_ce = torch.sum(y * (torch.digamma(S) - torch.digamma(alpha)), dim=1).mean()\n",
    "        \n",
    "        # KL regularization\n",
    "        alpha_tilde = y + (1 - y) * alpha\n",
    "        S_tilde = alpha_tilde.sum(dim=1, keepdim=True)\n",
    "        kl = torch.lgamma(S_tilde.squeeze()) - \\\n",
    "             torch.lgamma(torch.tensor(float(self.num_classes), device=alpha.device)) - \\\n",
    "             torch.sum(torch.lgamma(alpha_tilde), dim=1) + \\\n",
    "             torch.sum((alpha_tilde - 1) * (torch.digamma(alpha_tilde) - torch.digamma(S_tilde)), dim=1)\n",
    "        \n",
    "        annealing = min(1.0, self.epoch / Config.KL_ANNEALING_EPOCHS)\n",
    "        loss_kl = annealing * Config.LAMBDA_KL * kl.mean()\n",
    "        \n",
    "        # Focal loss\n",
    "        pt = torch.sum(y * probs, dim=1)\n",
    "        loss_focal = Config.LAMBDA_FOCAL * ((1 - pt) ** 2 * F.cross_entropy(\n",
    "            outputs['logits'], targets, reduction='none')).mean()\n",
    "        \n",
    "        return loss_ce + loss_kl + loss_focal, {'ce': loss_ce.item(), 'kl': loss_kl.item(), 'focal': loss_focal.item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94b919",
   "metadata": {},
   "source": [
    "## Metrics (FIXED AUC-ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ece(y_true, y_prob, n_bins=15):\n",
    "    \"\"\"Expected Calibration Error\"\"\"\n",
    "    confidences = np.max(y_prob, axis=1)\n",
    "    predictions = np.argmax(y_prob, axis=1)\n",
    "    accuracies = (predictions == y_true).astype(float)\n",
    "    \n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        in_bin = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i+1])\n",
    "        if in_bin.sum() > 0:\n",
    "            ece += np.abs(accuracies[in_bin].mean() - confidences[in_bin].mean()) * in_bin.mean()\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "def compute_metrics(y_true, y_pred, y_prob, uncertainties=None):\n",
    "    \"\"\"Compute all metrics with FIXED AUC-ROC\"\"\"\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred) * 100,\n",
    "        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0) * 100,\n",
    "        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0) * 100,\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0) * 100,\n",
    "        'cohen_kappa': cohen_kappa_score(y_true, y_pred),\n",
    "        'mcc': matthews_corrcoef(y_true, y_pred),\n",
    "    }\n",
    "    \n",
    "    # FIXED AUC-ROC\n",
    "    try:\n",
    "        metrics['auc_roc_macro'] = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
    "        metrics['auc_roc_weighted'] = roc_auc_score(y_true, y_prob, multi_class='ovr', average='weighted')\n",
    "        \n",
    "        # Per-class AUC\n",
    "        auc_per_class = []\n",
    "        for i in range(y_prob.shape[1]):\n",
    "            y_bin = (np.array(y_true) == i).astype(int)\n",
    "            if len(np.unique(y_bin)) > 1:\n",
    "                auc_per_class.append(roc_auc_score(y_bin, y_prob[:, i]))\n",
    "            else:\n",
    "                auc_per_class.append(np.nan)\n",
    "        metrics['auc_per_class'] = auc_per_class\n",
    "    except Exception as e:\n",
    "        print(f\"AUC warning: {e}\")\n",
    "        metrics['auc_roc_macro'] = np.nan\n",
    "    \n",
    "    # Per-class metrics\n",
    "    metrics['precision_per_class'] = (precision_score(y_true, y_pred, average=None, zero_division=0) * 100).tolist()\n",
    "    metrics['recall_per_class'] = (recall_score(y_true, y_pred, average=None, zero_division=0) * 100).tolist()\n",
    "    metrics['f1_per_class'] = (f1_score(y_true, y_pred, average=None, zero_division=0) * 100).tolist()\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    \n",
    "    # Calibration\n",
    "    metrics['ece'] = compute_ece(y_true, y_prob)\n",
    "    \n",
    "    # Uncertainty\n",
    "    if uncertainties is not None:\n",
    "        metrics['uncertainty_mean'] = float(np.mean(uncertainties))\n",
    "        correct = np.array(y_true) == np.array(y_pred)\n",
    "        metrics['uncertainty_correct'] = float(np.mean(uncertainties[correct]))\n",
    "        if (~correct).any():\n",
    "            metrics['uncertainty_incorrect'] = float(np.mean(uncertainties[~correct]))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52feb128",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scaler, device, epoch):\n",
    "    model.train()\n",
    "    criterion.set_epoch(epoch)\n",
    "    total_loss, all_labels, all_preds = 0, [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1} [Train]')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss, _ = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs['probs'].argmax(1).cpu().numpy())\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(loader), accuracy_score(all_labels, all_preds) * 100\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device, epoch=0):\n",
    "    model.eval()\n",
    "    criterion.set_epoch(epoch)\n",
    "    total_loss = 0\n",
    "    all_labels, all_preds, all_probs, all_unc = [], [], [], []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Validating'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss, _ = criterion(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs['probs'].argmax(1).cpu().numpy())\n",
    "        all_probs.extend(outputs['probs'].cpu().numpy())\n",
    "        all_unc.extend(outputs['uncertainty_total'].cpu().numpy())\n",
    "    \n",
    "    metrics = compute_metrics(np.array(all_labels), np.array(all_preds), \n",
    "                              np.array(all_probs), np.array(all_unc))\n",
    "    metrics['loss'] = total_loss / len(loader)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                device, epochs, save_path=None):\n",
    "    scaler = GradScaler()\n",
    "    best_acc = 0\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, device, epoch)\n",
    "        val_metrics = validate(model, val_loader, criterion, device, epoch)\n",
    "        scheduler.step()\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_metrics['loss'])\n",
    "        history['val_acc'].append(val_metrics['accuracy'])\n",
    "        history['val_auc'].append(val_metrics.get('auc_roc_macro', np.nan))\n",
    "        history['val_ece'].append(val_metrics['ece'])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "        print(f\"  Val: Loss={val_metrics['loss']:.4f}, Acc={val_metrics['accuracy']:.2f}%, \"\n",
    "              f\"AUC={val_metrics.get('auc_roc_macro', np.nan):.4f}, ECE={val_metrics['ece']:.4f}\")\n",
    "        \n",
    "        if val_metrics['accuracy'] > best_acc:\n",
    "            best_acc = val_metrics['accuracy']\n",
    "            if save_path:\n",
    "                torch.save({'model_state_dict': model.state_dict(), 'metrics': val_metrics}, save_path)\n",
    "                print(f\"  âœ“ Saved best model ({best_acc:.2f}%)\")\n",
    "    \n",
    "    return dict(history), best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f510b49",
   "metadata": {},
   "source": [
    "## Run Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.subset.dataset.samples[self.subset.indices[idx]]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def run_cross_validation(dataset, n_folds=5, epochs=30):\n",
    "    labels = [s[1] for s in dataset.samples]\n",
    "    indices = list(range(len(dataset)))\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=Config.SEED)\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(indices, labels)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"FOLD {fold + 1}/{n_folds}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        train_ds = TransformDataset(Subset(dataset, train_idx), get_transforms('train'))\n",
    "        val_ds = TransformDataset(Subset(dataset, val_idx), get_transforms('val'))\n",
    "        \n",
    "        # Fixed: num_workers=0 for Kaggle compatibility\n",
    "        train_loader = DataLoader(train_ds, Config.BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        val_loader = DataLoader(val_ds, Config.BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "        \n",
    "        model = HSANet().to(Config.DEVICE)\n",
    "        criterion = EvidentialLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "        \n",
    "        _, _ = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                           Config.DEVICE, epochs, Config.OUTPUT_DIR / f'fold_{fold+1}_best.pth')\n",
    "        \n",
    "        # Load best and evaluate - Fixed: weights_only=False for PyTorch 2.6+\n",
    "        ckpt = torch.load(Config.OUTPUT_DIR / f'fold_{fold+1}_best.pth', weights_only=False)\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "        final_metrics = validate(model, val_loader, criterion, Config.DEVICE)\n",
    "        fold_results.append(final_metrics)\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} Results: Acc={final_metrics['accuracy']:.2f}%, \"\n",
    "              f\"AUC={final_metrics['auc_roc_macro']:.4f}, ECE={final_metrics['ece']:.4f}\")\n",
    "    \n",
    "    # Aggregate\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CROSS-VALIDATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    for metric in ['accuracy', 'f1_macro', 'auc_roc_macro', 'ece', 'cohen_kappa']:\n",
    "        vals = [r[metric] for r in fold_results if not np.isnan(r.get(metric, np.nan))]\n",
    "        if vals:\n",
    "            print(f\"{metric}: {np.mean(vals):.4f} Â± {np.std(vals):.4f}\")\n",
    "    \n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation (set epochs lower for testing)\n",
    "cv_results = run_cross_validation(train_dataset, n_folds=5, epochs=Config.EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a83a7d",
   "metadata": {},
   "source": [
    "## Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ablation():\n",
    "    \"\"\"Run ablation study\"\"\"\n",
    "    # Create train/val split\n",
    "    labels = [s[1] for s in train_dataset.samples]\n",
    "    indices = list(range(len(train_dataset)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, stratify=labels, random_state=Config.SEED)\n",
    "    \n",
    "    train_ds = TransformDataset(Subset(train_dataset, train_idx), get_transforms('train'))\n",
    "    val_ds = TransformDataset(Subset(train_dataset, val_idx), get_transforms('val'))\n",
    "    \n",
    "    # Fixed: num_workers=0 for Kaggle compatibility\n",
    "    train_loader = DataLoader(train_ds, Config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, Config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    configs = [\n",
    "        {'name': 'Baseline', 'use_amsm': False, 'use_dam': False},\n",
    "        {'name': '+ AMSM', 'use_amsm': True, 'use_dam': False},\n",
    "        {'name': '+ DAM', 'use_amsm': False, 'use_dam': True},\n",
    "        {'name': 'HSANet (Full)', 'use_amsm': True, 'use_dam': True},\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for cfg in configs:\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Config: {cfg['name']}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        model = HSANet(use_amsm=cfg['use_amsm'], use_dam=cfg['use_dam']).to(Config.DEVICE)\n",
    "        params = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        criterion = EvidentialLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "        \n",
    "        _, _ = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                           Config.DEVICE, Config.EPOCHS)\n",
    "        \n",
    "        metrics = validate(model, val_loader, criterion, Config.DEVICE)\n",
    "        results.append({\n",
    "            'config': cfg['name'],\n",
    "            'params_M': params / 1e6,\n",
    "            'accuracy': metrics['accuracy'],\n",
    "            'f1': metrics['f1_macro'],\n",
    "            'auc': metrics['auc_roc_macro'],\n",
    "            'ece': metrics['ece']\n",
    "        })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ABLATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    df = pd.DataFrame(results)\n",
    "    print(df.to_string(index=False))\n",
    "    df.to_csv(Config.OUTPUT_DIR / 'ablation_results.csv', index=False)\n",
    "    return results\n",
    "\n",
    "ablation_results = run_ablation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f311f9f",
   "metadata": {},
   "source": [
    "## Final Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training set\n",
    "print(\"Training final model on full training set...\")\n",
    "\n",
    "full_train_ds = BrainTumorDataset(Config.DATA_DIR, 'Training', get_transforms('train'))\n",
    "# Fixed: num_workers=0 for Kaggle compatibility\n",
    "full_train_loader = DataLoader(full_train_ds, Config.BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "test_ds = BrainTumorDataset(Config.DATA_DIR, 'Testing', get_transforms('val'))\n",
    "test_loader = DataLoader(test_ds, Config.BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "final_model = HSANet().to(Config.DEVICE)\n",
    "criterion = EvidentialLoss()\n",
    "optimizer = torch.optim.AdamW(final_model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "_, _ = train_model(final_model, full_train_loader, test_loader, criterion, optimizer, scheduler,\n",
    "                   Config.DEVICE, Config.EPOCHS, Config.OUTPUT_DIR / 'hsanet_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca528a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate on test set - Fixed: weights_only=False for PyTorch 2.6+\n",
    "ckpt = torch.load(Config.OUTPUT_DIR / 'hsanet_final.pth', weights_only=False)\n",
    "final_model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "test_metrics = validate(final_model, test_loader, criterion, Config.DEVICE)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:     {test_metrics['accuracy']:.2f}%\")\n",
    "print(f\"Precision:    {test_metrics['precision_macro']:.2f}%\")\n",
    "print(f\"Recall:       {test_metrics['recall_macro']:.2f}%\")\n",
    "print(f\"F1-Score:     {test_metrics['f1_macro']:.2f}%\")\n",
    "print(f\"AUC-ROC:      {test_metrics['auc_roc_macro']:.4f}\")\n",
    "print(f\"Cohen Kappa:  {test_metrics['cohen_kappa']:.4f}\")\n",
    "print(f\"MCC:          {test_metrics['mcc']:.4f}\")\n",
    "print(f\"ECE:          {test_metrics['ece']:.4f}\")\n",
    "\n",
    "# Save test metrics\n",
    "with open(Config.OUTPUT_DIR / 'test_metrics.json', 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a89cc",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1095cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = np.array(test_metrics['confusion_matrix'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=Config.CLASS_NAMES_DISPLAY, yticklabels=Config.CLASS_NAMES_DISPLAY)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.OUTPUT_DIR / 'confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28686eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "final_model.eval()\n",
    "all_labels, all_probs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = final_model(images.to(Config.DEVICE))\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(outputs['probs'].cpu().numpy())\n",
    "\n",
    "y_true = np.array(all_labels)\n",
    "y_prob = np.array(all_probs)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, name in enumerate(Config.CLASS_NAMES_DISPLAY):\n",
    "    y_bin = (y_true == i).astype(int)\n",
    "    if len(np.unique(y_bin)) > 1:\n",
    "        fpr, tpr, _ = roc_curve(y_bin, y_prob[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.OUTPUT_DIR / 'roc_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3462b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reliability Diagram (Calibration)\n",
    "def plot_reliability_diagram(y_true, y_prob, n_bins=15):\n",
    "    confidences = np.max(y_prob, axis=1)\n",
    "    predictions = np.argmax(y_prob, axis=1)\n",
    "    accuracies = (predictions == y_true).astype(float)\n",
    "    \n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_centers = (bin_boundaries[:-1] + bin_boundaries[1:]) / 2\n",
    "    \n",
    "    bin_accs, bin_confs, bin_counts = [], [], []\n",
    "    for i in range(n_bins):\n",
    "        in_bin = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i+1])\n",
    "        if in_bin.sum() > 0:\n",
    "            bin_accs.append(accuracies[in_bin].mean())\n",
    "            bin_confs.append(confidences[in_bin].mean())\n",
    "            bin_counts.append(in_bin.sum())\n",
    "        else:\n",
    "            bin_accs.append(0)\n",
    "            bin_confs.append(bin_centers[i])\n",
    "            bin_counts.append(0)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax1.bar(bin_centers, bin_accs, width=1/n_bins, alpha=0.7, edgecolor='black')\n",
    "    ax1.plot([0, 1], [0, 1], 'r--', label='Perfect calibration')\n",
    "    ax1.set_xlabel('Confidence')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_title(f'Reliability Diagram (ECE = {compute_ece(y_true, y_prob):.4f})')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.bar(bin_centers, bin_counts, width=1/n_bins, alpha=0.7, edgecolor='black')\n",
    "    ax2.set_xlabel('Confidence')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Confidence Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Config.OUTPUT_DIR / 'reliability_diagram.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "plot_reliability_diagram(y_true, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10827c",
   "metadata": {},
   "source": [
    "## GradCAM Visualization (Interpretability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c76349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"GradCAM for HSANet interpretability\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        target_layer.register_forward_hook(self._save_activation)\n",
    "        target_layer.register_full_backward_hook(self._save_gradient)\n",
    "    \n",
    "    def _save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def _save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate(self, input_tensor, target_class=None):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = self.model(input_tensor)\n",
    "        probs = output['probs']\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = probs.argmax(dim=1).item()\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        one_hot = torch.zeros_like(probs)\n",
    "        one_hot[0, target_class] = 1\n",
    "        probs.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        # Generate heatmap\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        cam = F.interpolate(cam, size=input_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Normalize\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam, probs.detach().cpu().numpy()[0], output['uncertainty_total'].item()\n",
    "\n",
    "\n",
    "def visualize_gradcam(model, image_path, transform, device, save_path=None):\n",
    "    \"\"\"Generate GradCAM visualization for a single image\"\"\"\n",
    "    # Load and preprocess image\n",
    "    orig_img = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(orig_img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get the last layer of backbone for GradCAM\n",
    "    target_layer = model.backbone.blocks[-1]\n",
    "    \n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    heatmap, probs, uncertainty = gradcam.generate(input_tensor)\n",
    "    \n",
    "    pred_class = probs.argmax()\n",
    "    confidence = probs[pred_class]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(orig_img)\n",
    "    axes[0].set_title('Original MRI', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Heatmap\n",
    "    axes[1].imshow(heatmap, cmap='jet')\n",
    "    axes[1].set_title('GradCAM Heatmap', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    orig_resized = orig_img.resize((Config.IMG_SIZE, Config.IMG_SIZE))\n",
    "    orig_array = np.array(orig_resized) / 255.0\n",
    "    heatmap_colored = plt.cm.jet(heatmap)[:, :, :3]\n",
    "    overlay = 0.6 * orig_array + 0.4 * heatmap_colored\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    \n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(f'Prediction: {Config.CLASS_NAMES_DISPLAY[pred_class]}\\n'\n",
    "                      f'Confidence: {confidence:.2%} | Uncertainty: {uncertainty:.4f}', fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_class, confidence, uncertainty\n",
    "\n",
    "\n",
    "def generate_gradcam_grid(model, dataset, device, n_samples=3, save_path=None):\n",
    "    \"\"\"Generate GradCAM grid for multiple samples per class\"\"\"\n",
    "    model.eval()\n",
    "    transform = get_transforms('val')\n",
    "    \n",
    "    # Get samples per class\n",
    "    samples_per_class = {i: [] for i in range(Config.NUM_CLASSES)}\n",
    "    for img_path, label in dataset.samples:\n",
    "        if len(samples_per_class[label]) < n_samples:\n",
    "            samples_per_class[label].append(img_path)\n",
    "    \n",
    "    fig, axes = plt.subplots(Config.NUM_CLASSES, n_samples * 2, figsize=(4 * n_samples * 2, 4 * Config.NUM_CLASSES))\n",
    "    \n",
    "    for class_idx in range(Config.NUM_CLASSES):\n",
    "        for sample_idx, img_path in enumerate(samples_per_class[class_idx][:n_samples]):\n",
    "            # Load image\n",
    "            orig_img = Image.open(img_path).convert('RGB')\n",
    "            input_tensor = transform(orig_img).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get GradCAM\n",
    "            target_layer = model.backbone.blocks[-1]\n",
    "            gradcam = GradCAM(model, target_layer)\n",
    "            heatmap, probs, uncertainty = gradcam.generate(input_tensor)\n",
    "            \n",
    "            pred_class = probs.argmax()\n",
    "            confidence = probs[pred_class]\n",
    "            \n",
    "            # Original image column\n",
    "            col_orig = sample_idx * 2\n",
    "            axes[class_idx, col_orig].imshow(orig_img)\n",
    "            axes[class_idx, col_orig].axis('off')\n",
    "            if sample_idx == 0:\n",
    "                axes[class_idx, col_orig].set_ylabel(Config.CLASS_NAMES_DISPLAY[class_idx], fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Overlay column\n",
    "            col_overlay = sample_idx * 2 + 1\n",
    "            orig_resized = orig_img.resize((Config.IMG_SIZE, Config.IMG_SIZE))\n",
    "            orig_array = np.array(orig_resized) / 255.0\n",
    "            heatmap_colored = plt.cm.jet(heatmap)[:, :, :3]\n",
    "            overlay = 0.6 * orig_array + 0.4 * heatmap_colored\n",
    "            overlay = np.clip(overlay, 0, 1)\n",
    "            \n",
    "            axes[class_idx, col_overlay].imshow(overlay)\n",
    "            axes[class_idx, col_overlay].axis('off')\n",
    "            \n",
    "            # Add prediction info\n",
    "            correct = \"âœ“\" if pred_class == class_idx else \"âœ—\"\n",
    "            axes[class_idx, col_overlay].set_title(f'{correct} {confidence:.1%}', fontsize=10)\n",
    "    \n",
    "    # Add column headers\n",
    "    for i in range(n_samples):\n",
    "        axes[0, i*2].set_title(f'Sample {i+1}', fontsize=12)\n",
    "        axes[0, i*2+1].set_title(f'GradCAM {i+1}', fontsize=12)\n",
    "    \n",
    "    plt.suptitle('GradCAM Visualization Across All Classes', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"GradCAM visualization functions defined âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f594d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GradCAM grid for all classes (for paper figure)\n",
    "print(\"Generating GradCAM visualizations...\")\n",
    "generate_gradcam_grid(final_model, test_dataset, Config.DEVICE, n_samples=3, \n",
    "                      save_path=Config.OUTPUT_DIR / 'gradcam_grid.png')\n",
    "print(\"âœ“ Saved: gradcam_grid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate individual GradCAM examples (one per class for detailed view)\n",
    "print(\"\\nGenerating individual GradCAM examples...\")\n",
    "for class_idx, class_name in enumerate(Config.CLASS_NAMES):\n",
    "    # Find first sample of this class\n",
    "    for img_path, label in test_dataset.samples:\n",
    "        if label == class_idx:\n",
    "            save_name = Config.OUTPUT_DIR / f'gradcam_{class_name}.png'\n",
    "            visualize_gradcam(final_model, img_path, get_transforms('val'), \n",
    "                            Config.DEVICE, save_path=save_name)\n",
    "            print(f\"  âœ“ Saved: gradcam_{class_name}.png\")\n",
    "            break\n",
    "\n",
    "print(\"\\nâœ“ All GradCAM visualizations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a41003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nResults saved to: {Config.OUTPUT_DIR}\")\n",
    "print(\"\\nFiles:\")\n",
    "for f in Config.OUTPUT_DIR.glob('*'):\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6835cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all results as ZIP\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Create zip file directly in /kaggle/working/ (Kaggle's output directory)\n",
    "zip_filename = 'hsanet_results.zip'\n",
    "zip_path = f'/kaggle/working/{zip_filename}'\n",
    "\n",
    "# Create zip with all output files\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file in Config.OUTPUT_DIR.glob('*'):\n",
    "        if file.is_file():\n",
    "            zipf.write(file, file.name)\n",
    "            print(f\"  Added: {file.name}\")\n",
    "\n",
    "print(f\"\\nâœ… Created: {zip_path}\")\n",
    "print(f\"   Size: {os.path.getsize(zip_path) / 1024 / 1024:.2f} MB\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“¥ HOW TO DOWNLOAD:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Click 'Save Version' button (top right)\")\n",
    "print(\"2. After save completes, go to your notebook page\")\n",
    "print(\"3. Click 'Output' tab on the right panel\")\n",
    "print(\"4. Download 'hsanet_results.zip'\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
