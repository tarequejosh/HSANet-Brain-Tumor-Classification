{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Comparison: HSANet vs ViT, Swin, ResNet, VGG\n",
                "\n",
                "This notebook trains and evaluates multiple architectures for comparison.\n",
                "\n",
                "**Run on Kaggle with GPU enabled.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install timm -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from torchvision import transforms\n",
                "import timm\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from pathlib import Path\n",
                "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
                "from tqdm import tqdm\n",
                "import time\n",
                "import warnings\n",
                "import pandas as pd\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BrainTumorDataset(Dataset):\n",
                "    def __init__(self, root_dir, transform=None):\n",
                "        self.root_dir = Path(root_dir)\n",
                "        self.transform = transform\n",
                "        self.classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
                "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
                "        \n",
                "        self.samples = []\n",
                "        for class_name in self.classes:\n",
                "            class_dir = self.root_dir / class_name\n",
                "            if class_dir.exists():\n",
                "                for img_path in class_dir.glob('*.jpg'):\n",
                "                    self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
                "                for img_path in class_dir.glob('*.png'):\n",
                "                    self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
                "        \n",
                "        print(f\"Loaded {len(self.samples)} images from {root_dir}\")\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img_path, label = self.samples[idx]\n",
                "        image = Image.open(img_path).convert('RGB')\n",
                "        if self.transform:\n",
                "            image = self.transform(image)\n",
                "        return image, label"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "test_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Update paths for Kaggle\n",
                "TRAIN_DIR = '/kaggle/input/brain-tumor-mri-dataset/Training'\n",
                "TEST_DIR = '/kaggle/input/brain-tumor-mri-dataset/Testing'\n",
                "\n",
                "train_dataset = BrainTumorDataset(TRAIN_DIR, train_transform)\n",
                "test_dataset = BrainTumorDataset(TEST_DIR, test_transform)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
                "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"Train: {len(train_dataset)}, Test: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_and_evaluate(model_name, model, train_loader, test_loader, epochs=15):\n",
                "    \"\"\"Train a model and return metrics\"\"\"\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Training {model_name}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    model = model.to(device)\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
                "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
                "    \n",
                "    best_acc = 0\n",
                "    start_time = time.time()\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        train_loss = 0\n",
                "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            train_loss += loss.item()\n",
                "        \n",
                "        scheduler.step()\n",
                "        \n",
                "        model.eval()\n",
                "        all_preds, all_labels, all_probs = [], [], []\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            for images, labels in test_loader:\n",
                "                images = images.to(device)\n",
                "                outputs = model(images)\n",
                "                probs = torch.softmax(outputs, dim=1)\n",
                "                preds = outputs.argmax(dim=1)\n",
                "                \n",
                "                all_preds.extend(preds.cpu().numpy())\n",
                "                all_labels.extend(labels.numpy())\n",
                "                all_probs.extend(probs.cpu().numpy())\n",
                "        \n",
                "        acc = accuracy_score(all_labels, all_preds)\n",
                "        print(f\"  Epoch {epoch+1}: Loss={train_loss/len(train_loader):.4f}, Acc={acc:.4f}\")\n",
                "        \n",
                "        if acc > best_acc:\n",
                "            best_acc = acc\n",
                "            best_preds = all_preds\n",
                "            best_probs = all_probs\n",
                "            best_labels = all_labels\n",
                "    \n",
                "    training_time = time.time() - start_time\n",
                "    \n",
                "    f1 = f1_score(best_labels, best_preds, average='macro')\n",
                "    try:\n",
                "        auc = roc_auc_score(best_labels, best_probs, multi_class='ovr', average='macro')\n",
                "    except:\n",
                "        auc = 0.0\n",
                "    \n",
                "    # Inference time\n",
                "    model.eval()\n",
                "    dummy = torch.randn(1, 3, 224, 224).to(device)\n",
                "    for _ in range(10):  # warmup\n",
                "        _ = model(dummy)\n",
                "    \n",
                "    torch.cuda.synchronize()\n",
                "    start = time.time()\n",
                "    for _ in range(100):\n",
                "        _ = model(dummy)\n",
                "    torch.cuda.synchronize()\n",
                "    inference_time = (time.time() - start) / 100 * 1000\n",
                "    \n",
                "    params = sum(p.numel() for p in model.parameters()) / 1e6\n",
                "    \n",
                "    results = {\n",
                "        'model': model_name,\n",
                "        'accuracy': best_acc * 100,\n",
                "        'f1': f1 * 100,\n",
                "        'auc': auc,\n",
                "        'params_M': params,\n",
                "        'inference_ms': inference_time,\n",
                "    }\n",
                "    \n",
                "    print(f\"\\n{model_name} Results: Acc={results['accuracy']:.2f}%, F1={results['f1']:.2f}%, Params={params:.2f}M\")\n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train ViT-B/16\n",
                "vit_model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=4)\n",
                "vit_results = train_and_evaluate('ViT-B/16', vit_model, train_loader, test_loader, epochs=15)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Swin-Tiny\n",
                "swin_model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=4)\n",
                "swin_results = train_and_evaluate('Swin-Tiny', swin_model, train_loader, test_loader, epochs=15)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train ResNet-50\n",
                "resnet_model = timm.create_model('resnet50', pretrained=True, num_classes=4)\n",
                "resnet_results = train_and_evaluate('ResNet-50', resnet_model, train_loader, test_loader, epochs=15)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train VGG-16\n",
                "vgg_model = timm.create_model('vgg16', pretrained=True, num_classes=4)\n",
                "vgg_results = train_and_evaluate('VGG-16', vgg_model, train_loader, test_loader, epochs=15)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary\n",
                "all_results = [vit_results, swin_results, resnet_results, vgg_results]\n",
                "df = pd.DataFrame(all_results)\n",
                "df = df[['model', 'params_M', 'accuracy', 'f1', 'auc', 'inference_ms']]\n",
                "df.columns = ['Method', 'Params (M)', 'Accuracy (%)', 'F1 (%)', 'AUC-ROC', 'Inference (ms)']\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"FINAL RESULTS - Use these values in your paper!\")\n",
                "print(\"=\"*80)\n",
                "print(df.to_string(index=False))\n",
                "print(\"=\"*80)\n",
                "\n",
                "df.to_csv('comparison_results.csv', index=False)\n",
                "print(\"\\nResults saved to comparison_results.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}